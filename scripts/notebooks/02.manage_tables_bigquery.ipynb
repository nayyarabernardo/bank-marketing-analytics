{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria√ß√£o de Database e tabelas no BigQuery no GCP Usando Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json  \n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.api_core import exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credenciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_bigquery_credentials(\n",
    "    credentials_path: Optional[str] = None, \n",
    "    credentials_env_var: str = \"GOOGLE_APPLICATION_CREDENTIALS\",\n",
    "    verbose: bool = True\n",
    ") -> bigquery.Client:\n",
    "    \"\"\"\n",
    "    Configura as credenciais do BigQuery e inicializa o cliente. \n",
    "\n",
    "    Args:\n",
    "        credentials_path (str, opcional): Caminho para o arquivo de credenciais JSON\n",
    "        credentials_env_var (str, opcional): Nome da vari√°vel de ambiente para credenciais\n",
    "        verbose (bool, opcional): Exibir logs detalhados\n",
    "    \n",
    "    Returns:\n",
    "        bigquery.Client: Cliente do BigQuery\n",
    "    \"\"\"\n",
    "    # Configurar logging \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO if verbose else logging.WARNING,\n",
    "        format='%(asctime)s - %(levelname)s: %(message)s'\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    try:\n",
    "        # Se o caminho n√£o for fornecido, tenta usar localiza√ß√µes padr√£o \n",
    "        if credentials_path is None:\n",
    "            default_paths = [\n",
    "                \"../key.json\",\n",
    "                \"../../key.json\",\n",
    "                os.path.expanduser(\"~/key.json\")\n",
    "            ]\n",
    "            \n",
    "            for path in default_paths:\n",
    "                if os.path.exists(path):\n",
    "                    credentials_path = path\n",
    "                    break\n",
    "\n",
    "        # Validar exist√™ncia do arquivo de credenciais \n",
    "        if not credentials_path or not os.path.exists(credentials_path):\n",
    "            raise FileNotFoundError(f\"Arquivo de credenciais n√£o encontrado em {credentials_path}\")\n",
    "\n",
    "        # Configurar vari√°vel de ambiente \n",
    "        os.environ[credentials_env_var] = credentials_path\n",
    "        logger.info(f\" üîë Credenciais configuradas: {credentials_path}\")\n",
    "\n",
    "        # Inicializar cliente do BigQuery \n",
    "        bqclient = bigquery.Client()\n",
    "        \n",
    "        return bqclient\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao configurar credenciais: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria√ß√£o de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigquery_dataset(\n",
    "    client: bigquery.Client, \n",
    "    dataset_id: str, \n",
    "    location: str = \"US\",\n",
    "    verbose: bool = True\n",
    ") -> bigquery.Dataset:\n",
    "    \"\"\"\n",
    "    Cria um dataset no BigQuery, verificando se j√° existe. \n",
    "\n",
    "    Args:\n",
    "        client (bigquery.Client): Cliente do BigQuery\n",
    "        dataset_id (str): ID completo do dataset (projeto.dataset)\n",
    "        location (str, opcional): Localiza√ß√£o geogr√°fica do dataset\n",
    "        verbose (bool, opcional): Exibir logs detalhados\n",
    "\n",
    "    Returns:\n",
    "        bigquery.Dataset: Dataset criado ou existente\n",
    "    \"\"\"\n",
    "    # Configurar logging \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO if verbose else logging.WARNING,\n",
    "        format='%(asctime)s - %(levelname)s: %(message)s'\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    try:\n",
    "        # Construir objeto do Dataset \n",
    "        dataset = bigquery.Dataset(dataset_id)\n",
    "        dataset.location = location\n",
    "\n",
    "        try:\n",
    "            # Tentar criar dataset, capturando se j√° existir \n",
    "            dataset = client.create_dataset(dataset, timeout=30)\n",
    "            logger.info(f\"‚úÖ Dataset criado: {dataset_id}\")\n",
    "        except exceptions.Conflict:\n",
    "            logger.warning(f\"‚ö†Ô∏è Dataset {dataset_id} j√° existe. Usando o existente.\")\n",
    "            dataset = client.get_dataset(dataset_id)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro ao criar dataset: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria√ß√£o de Tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigquery_tables(\n",
    "    client: bigquery.Client, \n",
    "    dataset_id: str, \n",
    "    schema_path: str = 'schema.json',\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, bigquery.Table]:\n",
    "    \"\"\"\n",
    "    Cria tabelas no BigQuery a partir de um arquivo de schema JSON. \n",
    "\n",
    "    Args:\n",
    "        client (bigquery.Client): Cliente do BigQuery\n",
    "        dataset_id (str): ID do dataset onde as tabelas ser√£o criadas\n",
    "        schema_path (str): Caminho para o arquivo de schema JSON\n",
    "        verbose (bool, opcional): Exibir logs detalhados\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, bigquery.Table]: Dicion√°rio de tabelas criadas\n",
    "    \"\"\"\n",
    "    # Configurar logging \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO if verbose else logging.WARNING,\n",
    "        format='%(asctime)s - %(levelname)s: %(message)s'\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    try:\n",
    "        # Verificar exist√™ncia do arquivo de schema \n",
    "        if not os.path.exists(schema_path):\n",
    "            raise FileNotFoundError(f\"Arquivo de schema n√£o encontrado em: {schema_path}\")\n",
    "\n",
    "        # Carregar schema do arquivo JSON \n",
    "        with open(schema_path, 'r') as schema_file:\n",
    "            schemas = json.load(schema_file)\n",
    "\n",
    "        # Validar estrutura do schema \n",
    "        if not schemas or not isinstance(schemas, dict):\n",
    "            raise ValueError(\"Schema inv√°lido. Deve ser um dicion√°rio n√£o vazio.\")\n",
    "\n",
    "        created_tables = {}\n",
    "\n",
    "        # Iterar sobre as defini√ß√µes de tabela no schema \n",
    "        for table_name, table_info in schemas.items():\n",
    "            # Validar informa√ß√µes da tabela \n",
    "            if 'schema' not in table_info:\n",
    "                logger.warning(f\"‚ö†Ô∏è Pulando tabela {table_name}: Schema n√£o definido\")\n",
    "                continue\n",
    "\n",
    "            # Construir ID completo da tabela \n",
    "            full_table_id = f\"{dataset_id}.{table_name}\"\n",
    "            \n",
    "            # Criar objeto de tabela \n",
    "            table = bigquery.Table(full_table_id, schema=table_info['schema'])\n",
    "            table.description = table_info.get('description', '')\n",
    "\n",
    "            try:\n",
    "                # Tentar criar tabela \n",
    "                created_table = client.create_table(table)\n",
    "                logger.info(f\"‚úÖ Tabela criada: {full_table_id}\")\n",
    "                created_tables[table_name] = created_table\n",
    "            except exceptions.Conflict:\n",
    "                logger.warning(f\"‚ö†Ô∏è Tabela {full_table_id} j√° existe. Pulando...\")\n",
    "            except Exception as table_error:\n",
    "                logger.error(f\"‚ùå Erro ao criar tabela {full_table_id}: {table_error}\")\n",
    "\n",
    "        if not created_tables:\n",
    "            logger.warning(\"‚ö†Ô∏è Nenhuma tabela foi criada\")\n",
    "\n",
    "        return created_tables\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(\"‚ùå Erro ao decodificar o arquivo JSON de schema\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro ao criar tabelas: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 15:29:32,067 - INFO: Credenciais configuradas: ../../key.json\n",
      "2024-12-15 15:29:33,386 - INFO: ‚úÖ Dataset criado: bankmarketingdatapipeline.db_retail\n",
      "2024-12-15 15:29:33,797 - INFO: ‚úÖ Tabela criada: bankmarketingdatapipeline.db_retail.trusted_departments\n",
      "2024-12-15 15:29:34,288 - INFO: ‚úÖ Tabela criada: bankmarketingdatapipeline.db_retail.trusted_order\n",
      "2024-12-15 15:29:34,872 - INFO: ‚úÖ Tabela criada: bankmarketingdatapipeline.db_retail.trusted_categories\n",
      "2024-12-15 15:29:35,383 - INFO: ‚úÖ Tabela criada: bankmarketingdatapipeline.db_retail.trusted_products\n",
      "2024-12-15 15:29:35,793 - INFO: ‚úÖ Tabela criada: bankmarketingdatapipeline.db_retail.trusted_customers\n",
      "2024-12-15 15:29:36,179 - INFO: ‚úÖ Tabela criada: bankmarketingdatapipeline.db_retail.trusted_order_items\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Configurar credenciais e cliente\n",
    "        bq_client = setup_bigquery_credentials()\n",
    "\n",
    "        # Criar dataset \n",
    "        dataset_id = f\"{bq_client.project}.db_retail\"\n",
    "        dataset = create_bigquery_dataset(bq_client, dataset_id)\n",
    "\n",
    "        # Criar tabelas \n",
    "        tables = create_bigquery_tables(bq_client, dataset_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no processo: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
